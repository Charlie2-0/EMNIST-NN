function [J, grad] = costFunct(X, y_matrix, nntheta, lambda,funct, functgrad,hidden_layers,t_rows,t_cols,ts)
%cost function performs L2 regularization
%reshape the first theta
theta{1} = reshape(nntheta(1:t_rows(1)* t_cols(1)), [t_rows(1), t_cols(1)]);
%reshape the remaining thetas
for i=2:ts
[sum(t_rows(1:i-1).*t_cols(1:i-1))+1,sum(t_rows(1:i).*t_cols(1:i)),i]
size(nntheta(sum(t_rows(1:i-1).*t_cols(1:i-1))+1:sum(sum(t_rows(1:i-1).*t_cols(1:i-1)) ...
+(t_rows(i)* t_cols(i)))))
[t_rows(i), t_cols(i),t_rows(i)*t_cols(i)]
    theta{i} = reshape(nntheta(sum(t_rows(1:i-1).*t_cols(1:i-1))+1:sum(sum(t_rows(1:i-1).*t_cols(1:i-1)) ...
    +(t_rows(i)* t_cols(i)))), [t_rows(i), t_cols(i)]);

end

%feedforward

[htheta,a,z] = feedforward(X,theta,funct,ts);

m =  size(X,1);   
%(87360x26)*(
J = (1/m).*(-sum(sum(y_matrix.*log(htheta))) - sum(sum((1-y_matrix).*(log(1-htheta)))));
    
    [b, ts] = size(theta);
total = 0;
    for i = 1:ts
        temp = theta{i};
        tempsum = sum(sum(temp.^2));
        total = total+tempsum;
    end
    
    reg = (lambda/m).*total;
    
    J = J+reg;
        
%back prop
%find the error between prediction and ground truth
Thetagrad = cell(1,hidden_layers+1);
Thetagrad(1,:) = {0};
d{hidden_layers+2} = htheta - y_matrix; %87360x26
d{hidden_layers+1} = (d{hidden_layers+2}*theta{hidden_layers+1}).*[ones(size(z{hidden_layers+1},1),1) functgrad(z{hidden_layers+1})];
D{hidden_layers+1} = d{hidden_layers+2}(:,2:end)'*a{hidden_layers+1};
%collect the grads
Thetagrad{hidden_layers+1} = Thetagrad{hidden_layers+1} + (1/m)*D{hidden_layers+1};
%reg the grad
Thetagrad{hidden_layers+1}(:,2:end) =  Thetagrad{hidden_layers+1}(:,2:end) + (lambda/m)*(Thetagrad{hidden_layers+1}(:,2:end));
%back prop the remaining layers

for i = 1:hidden_layers -1
    [hidden_layers+1-i, size(d{hidden_layers+2-i}), size(theta{hidden_layers+1-i}), size([ones(size(z{hidden_layers+1-i},1),1) functgrad(z{hidden_layers+1 - i})])]
    %d5 = d6*theta5.*[ones(size(z{5},1),1) functgrad(z{5})]
    %d5 = (87360x26) * (26x8) .* (87360x27) = (87360x8).*(87360x8)
    %d4 = d5*theta4.*[ones(size(z{4},1),1) functgrad(z{4})]
    %d4 = (87360x7) * 
    %(8x26)*
    d{hidden_layers+1 - i} = (d{hidden_layers+2-i}(:,2:end)*theta{hidden_layers+1-i}).*[ones(size(z{hidden_layers+1-i},1),1) functgrad(z{hidden_layers+1 - i})];
    D{hidden_layers+1 - i} = d{hidden_layers+2-i}(:,2:end)'*a{hidden_layers+1 - i};
    %collect the grads
    Thetagrad{hidden_layers+1-i} = Thetagrad{hidden_layers+1-i} + (1/m)*D{hidden_layers+1-i};
    %reg the grad
    Thetagrad{hidden_layers+1-i}(:,2:end) =  Thetagrad{hidden_layers+1-i}(:,2:end) + (lambda/m)*(Thetagrad{hidden_layers+1-i}(:,2:end));
end
%last layer
D{1} = d{2}(:,2:end)'*a{1};
%collect the grads
Thetagrad{1} = Thetagrad{1} + (1/m)*D{1};
%reg the grad
Thetagrad{1}(:,2:end) =  Thetagrad{1}(:,2:end) + (lambda/m)*(Thetagrad{1}(:,2:end));
%create a vector of ref values for each grad
g_rows = [];
g_cols = [];
 for i = 1:ts
 
     [rows, cols] = size(Thetagrad{i});
     g_rows = [g_rows;rows];
     g_cols = [g_cols;cols];
 
 end
%unroll the grads
grad = [];
for i = 1:hidden_layers+1
grad = [grad; Thetagrad{i}(:)];
end
%unroll the ts
nntheta = [];
for i = 1:hidden_layers+1
nntheta = [nntheta; theta{i}(:)];
end
end